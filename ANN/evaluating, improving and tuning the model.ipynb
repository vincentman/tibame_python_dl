{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取客户流失数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "df = pandas.read_csv('../data/customer_churn.csv', index_col=0, header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据前处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = ['international_plan','voice_mail_plan', 'churn']\n",
    "\n",
    "for var in cat_var:\n",
    "    df[var] = df[var].map(lambda e: 1 if e == 'yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.iloc[:,-1]\n",
    "x = df.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 区分训练与测试数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.33, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尺度标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.fit_transform(x_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold 交叉验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildClassifier(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 16))\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1786/1786 [==============================] - 2s 983us/step - loss: 0.6218 - acc: 0.8494\n",
      "Epoch 2/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3924 - acc: 0.8527\n",
      "Epoch 3/100\n",
      "1786/1786 [==============================] - 0s 183us/step - loss: 0.3443 - acc: 0.8527\n",
      "Epoch 4/100\n",
      "1786/1786 [==============================] - 0s 183us/step - loss: 0.3370 - acc: 0.8527\n",
      "Epoch 5/100\n",
      "1786/1786 [==============================] - 0s 181us/step - loss: 0.3324 - acc: 0.8527\n",
      "Epoch 6/100\n",
      "1786/1786 [==============================] - 0s 185us/step - loss: 0.3276 - acc: 0.8527\n",
      "Epoch 7/100\n",
      "1786/1786 [==============================] - 0s 186us/step - loss: 0.3246 - acc: 0.8527\n",
      "Epoch 8/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3219 - acc: 0.8527\n",
      "Epoch 9/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3191 - acc: 0.8662\n",
      "Epoch 10/100\n",
      "1786/1786 [==============================] - 0s 208us/step - loss: 0.3172 - acc: 0.8684\n",
      "Epoch 11/100\n",
      "1786/1786 [==============================] - 0s 197us/step - loss: 0.3157 - acc: 0.8707\n",
      "Epoch 12/100\n",
      "1786/1786 [==============================] - 0s 177us/step - loss: 0.3141 - acc: 0.8740\n",
      "Epoch 13/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3128 - acc: 0.8740\n",
      "Epoch 14/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3115 - acc: 0.8751\n",
      "Epoch 15/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3108 - acc: 0.8735\n",
      "Epoch 16/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3095 - acc: 0.8735\n",
      "Epoch 17/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3079 - acc: 0.8751\n",
      "Epoch 18/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3066 - acc: 0.8757\n",
      "Epoch 19/100\n",
      "1786/1786 [==============================] - 0s 197us/step - loss: 0.3063 - acc: 0.8735\n",
      "Epoch 20/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3048 - acc: 0.8768\n",
      "Epoch 21/100\n",
      "1786/1786 [==============================] - 0s 199us/step - loss: 0.3041 - acc: 0.8740\n",
      "Epoch 22/100\n",
      "1786/1786 [==============================] - 0s 195us/step - loss: 0.3032 - acc: 0.8757\n",
      "Epoch 23/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3021 - acc: 0.8802\n",
      "Epoch 24/100\n",
      "1786/1786 [==============================] - 0s 197us/step - loss: 0.3014 - acc: 0.8791\n",
      "Epoch 25/100\n",
      "1786/1786 [==============================] - 0s 209us/step - loss: 0.3002 - acc: 0.8785\n",
      "Epoch 26/100\n",
      "1786/1786 [==============================] - 0s 204us/step - loss: 0.2989 - acc: 0.8796\n",
      "Epoch 27/100\n",
      "1786/1786 [==============================] - 0s 209us/step - loss: 0.2986 - acc: 0.8824\n",
      "Epoch 28/100\n",
      "1786/1786 [==============================] - 0s 229us/step - loss: 0.2973 - acc: 0.8819\n",
      "Epoch 29/100\n",
      "1786/1786 [==============================] - 0s 215us/step - loss: 0.2950 - acc: 0.8830\n",
      "Epoch 30/100\n",
      "1786/1786 [==============================] - 0s 223us/step - loss: 0.2927 - acc: 0.8869\n",
      "Epoch 31/100\n",
      "1786/1786 [==============================] - 0s 219us/step - loss: 0.2904 - acc: 0.8897\n",
      "Epoch 32/100\n",
      "1786/1786 [==============================] - 0s 215us/step - loss: 0.2875 - acc: 0.8919\n",
      "Epoch 33/100\n",
      "1786/1786 [==============================] - 0s 218us/step - loss: 0.2845 - acc: 0.8931\n",
      "Epoch 34/100\n",
      "1786/1786 [==============================] - 0s 217us/step - loss: 0.2818 - acc: 0.8970\n",
      "Epoch 35/100\n",
      "1786/1786 [==============================] - 0s 224us/step - loss: 0.2792 - acc: 0.8964\n",
      "Epoch 36/100\n",
      "1786/1786 [==============================] - 0s 223us/step - loss: 0.2756 - acc: 0.9015\n",
      "Epoch 37/100\n",
      "1786/1786 [==============================] - 0s 222us/step - loss: 0.2727 - acc: 0.9015\n",
      "Epoch 38/100\n",
      "1786/1786 [==============================] - 0s 221us/step - loss: 0.2703 - acc: 0.9031\n",
      "Epoch 39/100\n",
      "1786/1786 [==============================] - 0s 222us/step - loss: 0.2674 - acc: 0.9059\n",
      "Epoch 40/100\n",
      "1786/1786 [==============================] - 0s 224us/step - loss: 0.2648 - acc: 0.9065\n",
      "Epoch 41/100\n",
      "1786/1786 [==============================] - 0s 216us/step - loss: 0.2617 - acc: 0.9087\n",
      "Epoch 42/100\n",
      "1786/1786 [==============================] - 0s 217us/step - loss: 0.2598 - acc: 0.9065\n",
      "Epoch 43/100\n",
      "1786/1786 [==============================] - 0s 233us/step - loss: 0.2571 - acc: 0.9093\n",
      "Epoch 44/100\n",
      "1786/1786 [==============================] - 0s 227us/step - loss: 0.2547 - acc: 0.9121\n",
      "Epoch 45/100\n",
      "1786/1786 [==============================] - 0s 225us/step - loss: 0.2512 - acc: 0.9115\n",
      "Epoch 46/100\n",
      "1786/1786 [==============================] - 0s 231us/step - loss: 0.2475 - acc: 0.9127\n",
      "Epoch 47/100\n",
      "1786/1786 [==============================] - 0s 215us/step - loss: 0.2444 - acc: 0.9143\n",
      "Epoch 48/100\n",
      "1786/1786 [==============================] - 0s 225us/step - loss: 0.2403 - acc: 0.9127\n",
      "Epoch 49/100\n",
      "1786/1786 [==============================] - 0s 195us/step - loss: 0.2356 - acc: 0.9155\n",
      "Epoch 50/100\n",
      "1786/1786 [==============================] - 0s 197us/step - loss: 0.2314 - acc: 0.9188\n",
      "Epoch 51/100\n",
      "1786/1786 [==============================] - 0s 193us/step - loss: 0.2273 - acc: 0.9155\n",
      "Epoch 52/100\n",
      "1786/1786 [==============================] - 0s 204us/step - loss: 0.2227 - acc: 0.9188\n",
      "Epoch 53/100\n",
      "1786/1786 [==============================] - 0s 208us/step - loss: 0.2205 - acc: 0.9183\n",
      "Epoch 54/100\n",
      "1786/1786 [==============================] - 0s 212us/step - loss: 0.2165 - acc: 0.9222\n",
      "Epoch 55/100\n",
      "1786/1786 [==============================] - 0s 198us/step - loss: 0.2138 - acc: 0.9216\n",
      "Epoch 56/100\n",
      "1786/1786 [==============================] - 0s 180us/step - loss: 0.2115 - acc: 0.9227\n",
      "Epoch 57/100\n",
      "1786/1786 [==============================] - 0s 174us/step - loss: 0.2101 - acc: 0.9216\n",
      "Epoch 58/100\n",
      "1786/1786 [==============================] - 0s 183us/step - loss: 0.2084 - acc: 0.9244\n",
      "Epoch 59/100\n",
      "1786/1786 [==============================] - 0s 181us/step - loss: 0.2065 - acc: 0.9239\n",
      "Epoch 60/100\n",
      "1786/1786 [==============================] - 0s 193us/step - loss: 0.2061 - acc: 0.9233\n",
      "Epoch 61/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.2038 - acc: 0.9317\n",
      "Epoch 62/100\n",
      "1786/1786 [==============================] - 0s 194us/step - loss: 0.2029 - acc: 0.9311\n",
      "Epoch 63/100\n",
      "1786/1786 [==============================] - 0s 180us/step - loss: 0.2006 - acc: 0.9317\n",
      "Epoch 64/100\n",
      "1786/1786 [==============================] - 0s 194us/step - loss: 0.2001 - acc: 0.9328\n",
      "Epoch 65/100\n",
      "1786/1786 [==============================] - 0s 205us/step - loss: 0.1981 - acc: 0.9334\n",
      "Epoch 66/100\n",
      "1786/1786 [==============================] - 0s 193us/step - loss: 0.1976 - acc: 0.9323\n",
      "Epoch 67/100\n",
      "1786/1786 [==============================] - 0s 213us/step - loss: 0.1955 - acc: 0.9317\n",
      "Epoch 68/100\n",
      "1786/1786 [==============================] - 0s 195us/step - loss: 0.1943 - acc: 0.9362\n",
      "Epoch 69/100\n",
      "1786/1786 [==============================] - 0s 209us/step - loss: 0.1943 - acc: 0.9362\n",
      "Epoch 70/100\n",
      "1786/1786 [==============================] - 0s 203us/step - loss: 0.1925 - acc: 0.9367\n",
      "Epoch 71/100\n",
      "1786/1786 [==============================] - 0s 194us/step - loss: 0.1926 - acc: 0.9367\n",
      "Epoch 72/100\n",
      "1786/1786 [==============================] - 0s 185us/step - loss: 0.1910 - acc: 0.9339\n",
      "Epoch 73/100\n",
      "1786/1786 [==============================] - 0s 193us/step - loss: 0.1908 - acc: 0.9367\n",
      "Epoch 74/100\n",
      "1786/1786 [==============================] - 0s 199us/step - loss: 0.1888 - acc: 0.9384\n",
      "Epoch 75/100\n",
      "1786/1786 [==============================] - 0s 184us/step - loss: 0.1882 - acc: 0.9367\n",
      "Epoch 76/100\n",
      "1786/1786 [==============================] - 0s 180us/step - loss: 0.1880 - acc: 0.9373\n",
      "Epoch 77/100\n",
      "1786/1786 [==============================] - 0s 211us/step - loss: 0.1857 - acc: 0.9406\n",
      "Epoch 78/100\n",
      "1786/1786 [==============================] - 0s 214us/step - loss: 0.1855 - acc: 0.9384\n",
      "Epoch 79/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.1831 - acc: 0.9367\n",
      "Epoch 80/100\n",
      "1786/1786 [==============================] - 0s 201us/step - loss: 0.1831 - acc: 0.9367\n",
      "Epoch 81/100\n",
      "1786/1786 [==============================] - 0s 200us/step - loss: 0.1823 - acc: 0.9406\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1786/1786 [==============================] - 0s 205us/step - loss: 0.1820 - acc: 0.9384\n",
      "Epoch 83/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.1817 - acc: 0.9395\n",
      "Epoch 84/100\n",
      "1786/1786 [==============================] - 0s 194us/step - loss: 0.1806 - acc: 0.9406\n",
      "Epoch 85/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.1779 - acc: 0.9406\n",
      "Epoch 86/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.1774 - acc: 0.9412\n",
      "Epoch 87/100\n",
      "1786/1786 [==============================] - 0s 186us/step - loss: 0.1786 - acc: 0.9412\n",
      "Epoch 88/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.1764 - acc: 0.9418\n",
      "Epoch 89/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.1770 - acc: 0.9423\n",
      "Epoch 90/100\n",
      "1786/1786 [==============================] - 0s 194us/step - loss: 0.1752 - acc: 0.9440\n",
      "Epoch 91/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.1752 - acc: 0.9429\n",
      "Epoch 92/100\n",
      "1786/1786 [==============================] - 0s 198us/step - loss: 0.1745 - acc: 0.9451\n",
      "Epoch 93/100\n",
      "1786/1786 [==============================] - 0s 205us/step - loss: 0.1731 - acc: 0.9446\n",
      "Epoch 94/100\n",
      "1786/1786 [==============================] - 0s 199us/step - loss: 0.1725 - acc: 0.9429\n",
      "Epoch 95/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.1741 - acc: 0.9429\n",
      "Epoch 96/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.1721 - acc: 0.9446\n",
      "Epoch 97/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.1722 - acc: 0.9440\n",
      "Epoch 98/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.1723 - acc: 0.9429\n",
      "Epoch 99/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.1699 - acc: 0.9457\n",
      "Epoch 100/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.1707 - acc: 0.9462\n",
      "447/447 [==============================] - 1s 1ms/step\n",
      "Epoch 1/100\n",
      "1786/1786 [==============================] - 2s 987us/step - loss: 0.5887 - acc: 0.8449\n",
      "Epoch 2/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3641 - acc: 0.8505\n",
      "Epoch 3/100\n",
      "1786/1786 [==============================] - 0s 174us/step - loss: 0.3444 - acc: 0.8505\n",
      "Epoch 4/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.3380 - acc: 0.8505\n",
      "Epoch 5/100\n",
      "1786/1786 [==============================] - 0s 174us/step - loss: 0.3351 - acc: 0.8505\n",
      "Epoch 6/100\n",
      "1786/1786 [==============================] - 0s 175us/step - loss: 0.3328 - acc: 0.8505\n",
      "Epoch 7/100\n",
      "1786/1786 [==============================] - 0s 176us/step - loss: 0.3316 - acc: 0.8505\n",
      "Epoch 8/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.3291 - acc: 0.8505\n",
      "Epoch 9/100\n",
      "1786/1786 [==============================] - 0s 171us/step - loss: 0.3282 - acc: 0.8505\n",
      "Epoch 10/100\n",
      "1786/1786 [==============================] - 0s 175us/step - loss: 0.3267 - acc: 0.8505\n",
      "Epoch 11/100\n",
      "1786/1786 [==============================] - 0s 171us/step - loss: 0.3260 - acc: 0.8505\n",
      "Epoch 12/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.3243 - acc: 0.8505\n",
      "Epoch 13/100\n",
      "1786/1786 [==============================] - 0s 182us/step - loss: 0.3242 - acc: 0.8505\n",
      "Epoch 14/100\n",
      "1786/1786 [==============================] - 0s 198us/step - loss: 0.3238 - acc: 0.8494\n",
      "Epoch 15/100\n",
      "1786/1786 [==============================] - 0s 177us/step - loss: 0.3232 - acc: 0.8533\n",
      "Epoch 16/100\n",
      "1786/1786 [==============================] - 0s 180us/step - loss: 0.3226 - acc: 0.8617\n",
      "Epoch 17/100\n",
      "1786/1786 [==============================] - 0s 176us/step - loss: 0.3224 - acc: 0.8589\n",
      "Epoch 18/100\n",
      "1786/1786 [==============================] - 0s 179us/step - loss: 0.3217 - acc: 0.8628\n",
      "Epoch 19/100\n",
      "1786/1786 [==============================] - 0s 180us/step - loss: 0.3211 - acc: 0.8628\n",
      "Epoch 20/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3202 - acc: 0.8656\n",
      "Epoch 21/100\n",
      "1786/1786 [==============================] - 0s 179us/step - loss: 0.3195 - acc: 0.8656\n",
      "Epoch 22/100\n",
      "1786/1786 [==============================] - 0s 174us/step - loss: 0.3199 - acc: 0.8667\n",
      "Epoch 23/100\n",
      "1786/1786 [==============================] - 0s 179us/step - loss: 0.3192 - acc: 0.8679\n",
      "Epoch 24/100\n",
      "1786/1786 [==============================] - 0s 181us/step - loss: 0.3195 - acc: 0.8662\n",
      "Epoch 25/100\n",
      "1786/1786 [==============================] - 0s 182us/step - loss: 0.3184 - acc: 0.8679\n",
      "Epoch 26/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3177 - acc: 0.8701\n",
      "Epoch 27/100\n",
      "1786/1786 [==============================] - 0s 184us/step - loss: 0.3168 - acc: 0.8701\n",
      "Epoch 28/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3170 - acc: 0.8718\n",
      "Epoch 29/100\n",
      "1786/1786 [==============================] - 0s 193us/step - loss: 0.3166 - acc: 0.8701\n",
      "Epoch 30/100\n",
      "1786/1786 [==============================] - 0s 208us/step - loss: 0.3157 - acc: 0.8729\n",
      "Epoch 31/100\n",
      "1786/1786 [==============================] - 0s 193us/step - loss: 0.3155 - acc: 0.8695\n",
      "Epoch 32/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3158 - acc: 0.8712\n",
      "Epoch 33/100\n",
      "1786/1786 [==============================] - 0s 194us/step - loss: 0.3153 - acc: 0.8718\n",
      "Epoch 34/100\n",
      "1786/1786 [==============================] - 0s 215us/step - loss: 0.3150 - acc: 0.8735\n",
      "Epoch 35/100\n",
      "1786/1786 [==============================] - 0s 219us/step - loss: 0.3142 - acc: 0.8751\n",
      "Epoch 36/100\n",
      "1786/1786 [==============================] - 0s 210us/step - loss: 0.3137 - acc: 0.8746\n",
      "Epoch 37/100\n",
      "1786/1786 [==============================] - 0s 212us/step - loss: 0.3136 - acc: 0.8746\n",
      "Epoch 38/100\n",
      "1786/1786 [==============================] - 0s 211us/step - loss: 0.3131 - acc: 0.8751\n",
      "Epoch 39/100\n",
      "1786/1786 [==============================] - 0s 215us/step - loss: 0.3127 - acc: 0.8763\n",
      "Epoch 40/100\n",
      "1786/1786 [==============================] - 0s 211us/step - loss: 0.3125 - acc: 0.8740\n",
      "Epoch 41/100\n",
      "1786/1786 [==============================] - 0s 211us/step - loss: 0.3120 - acc: 0.8763\n",
      "Epoch 42/100\n",
      "1786/1786 [==============================] - 0s 208us/step - loss: 0.3120 - acc: 0.8757\n",
      "Epoch 43/100\n",
      "1786/1786 [==============================] - 0s 201us/step - loss: 0.3117 - acc: 0.8779\n",
      "Epoch 44/100\n",
      "1786/1786 [==============================] - 0s 205us/step - loss: 0.3112 - acc: 0.8791\n",
      "Epoch 45/100\n",
      "1786/1786 [==============================] - 0s 200us/step - loss: 0.3110 - acc: 0.8796\n",
      "Epoch 46/100\n",
      "1786/1786 [==============================] - 0s 203us/step - loss: 0.3111 - acc: 0.8768\n",
      "Epoch 47/100\n",
      "1786/1786 [==============================] - 0s 201us/step - loss: 0.3103 - acc: 0.8757\n",
      "Epoch 48/100\n",
      "1786/1786 [==============================] - 0s 208us/step - loss: 0.3100 - acc: 0.8802\n",
      "Epoch 49/100\n",
      "1786/1786 [==============================] - 0s 206us/step - loss: 0.3105 - acc: 0.8791\n",
      "Epoch 50/100\n",
      "1786/1786 [==============================] - 0s 203us/step - loss: 0.3102 - acc: 0.8779\n",
      "Epoch 51/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3106 - acc: 0.8768\n",
      "Epoch 52/100\n",
      "1786/1786 [==============================] - 0s 194us/step - loss: 0.3099 - acc: 0.8802\n",
      "Epoch 53/100\n",
      "1786/1786 [==============================] - 0s 193us/step - loss: 0.3092 - acc: 0.8779\n",
      "Epoch 54/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3096 - acc: 0.8802\n",
      "Epoch 55/100\n",
      "1786/1786 [==============================] - 0s 199us/step - loss: 0.3091 - acc: 0.8830\n",
      "Epoch 56/100\n",
      "1786/1786 [==============================] - 0s 209us/step - loss: 0.3092 - acc: 0.8813\n",
      "Epoch 57/100\n",
      "1786/1786 [==============================] - 0s 215us/step - loss: 0.3083 - acc: 0.8830\n",
      "Epoch 58/100\n",
      "1786/1786 [==============================] - 0s 235us/step - loss: 0.3084 - acc: 0.8830\n",
      "Epoch 59/100\n",
      "1786/1786 [==============================] - 0s 230us/step - loss: 0.3081 - acc: 0.8847\n",
      "Epoch 60/100\n",
      "1786/1786 [==============================] - 0s 232us/step - loss: 0.3080 - acc: 0.8830\n",
      "Epoch 61/100\n",
      "1786/1786 [==============================] - 0s 237us/step - loss: 0.3080 - acc: 0.8830\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1786/1786 [==============================] - 0s 241us/step - loss: 0.3077 - acc: 0.8835\n",
      "Epoch 63/100\n",
      "1786/1786 [==============================] - 0s 237us/step - loss: 0.3076 - acc: 0.8841\n",
      "Epoch 64/100\n",
      "1786/1786 [==============================] - 0s 241us/step - loss: 0.3073 - acc: 0.8869\n",
      "Epoch 65/100\n",
      "1786/1786 [==============================] - 0s 210us/step - loss: 0.3069 - acc: 0.8852\n",
      "Epoch 66/100\n",
      "1786/1786 [==============================] - 0s 201us/step - loss: 0.3072 - acc: 0.8875\n",
      "Epoch 67/100\n",
      "1786/1786 [==============================] - 0s 193us/step - loss: 0.3065 - acc: 0.8847\n",
      "Epoch 68/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3064 - acc: 0.8886\n",
      "Epoch 69/100\n",
      "1786/1786 [==============================] - 0s 183us/step - loss: 0.3067 - acc: 0.8830\n",
      "Epoch 70/100\n",
      "1786/1786 [==============================] - 0s 185us/step - loss: 0.3061 - acc: 0.8869\n",
      "Epoch 71/100\n",
      "1786/1786 [==============================] - 0s 181us/step - loss: 0.3058 - acc: 0.8858\n",
      "Epoch 72/100\n",
      "1786/1786 [==============================] - 0s 181us/step - loss: 0.3055 - acc: 0.8863\n",
      "Epoch 73/100\n",
      "1786/1786 [==============================] - 0s 186us/step - loss: 0.3066 - acc: 0.8852\n",
      "Epoch 74/100\n",
      "1786/1786 [==============================] - 0s 174us/step - loss: 0.3053 - acc: 0.8852\n",
      "Epoch 75/100\n",
      "1786/1786 [==============================] - 0s 174us/step - loss: 0.3048 - acc: 0.8875\n",
      "Epoch 76/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.3046 - acc: 0.8880\n",
      "Epoch 77/100\n",
      "1786/1786 [==============================] - 0s 178us/step - loss: 0.3048 - acc: 0.8880\n",
      "Epoch 78/100\n",
      "1786/1786 [==============================] - 0s 166us/step - loss: 0.3049 - acc: 0.8852\n",
      "Epoch 79/100\n",
      "1786/1786 [==============================] - 0s 165us/step - loss: 0.3037 - acc: 0.8875\n",
      "Epoch 80/100\n",
      "1786/1786 [==============================] - 0s 171us/step - loss: 0.3033 - acc: 0.8869\n",
      "Epoch 81/100\n",
      "1786/1786 [==============================] - 0s 166us/step - loss: 0.3036 - acc: 0.8891\n",
      "Epoch 82/100\n",
      "1786/1786 [==============================] - 0s 170us/step - loss: 0.3034 - acc: 0.8886\n",
      "Epoch 83/100\n",
      "1786/1786 [==============================] - 0s 166us/step - loss: 0.3029 - acc: 0.8897\n",
      "Epoch 84/100\n",
      "1786/1786 [==============================] - 0s 174us/step - loss: 0.3022 - acc: 0.8875\n",
      "Epoch 85/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.3022 - acc: 0.8869\n",
      "Epoch 86/100\n",
      "1786/1786 [==============================] - 0s 175us/step - loss: 0.3027 - acc: 0.8875\n",
      "Epoch 87/100\n",
      "1786/1786 [==============================] - 0s 176us/step - loss: 0.3010 - acc: 0.8897\n",
      "Epoch 88/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.2999 - acc: 0.8897\n",
      "Epoch 89/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.3014 - acc: 0.8897\n",
      "Epoch 90/100\n",
      "1786/1786 [==============================] - 0s 175us/step - loss: 0.3004 - acc: 0.8869\n",
      "Epoch 91/100\n",
      "1786/1786 [==============================] - 0s 174us/step - loss: 0.2993 - acc: 0.8903\n",
      "Epoch 92/100\n",
      "1786/1786 [==============================] - 0s 175us/step - loss: 0.2989 - acc: 0.8886\n",
      "Epoch 93/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.2985 - acc: 0.8903\n",
      "Epoch 94/100\n",
      "1786/1786 [==============================] - 0s 174us/step - loss: 0.2979 - acc: 0.8903\n",
      "Epoch 95/100\n",
      "1786/1786 [==============================] - 0s 178us/step - loss: 0.2972 - acc: 0.8891\n",
      "Epoch 96/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.2965 - acc: 0.8953\n",
      "Epoch 97/100\n",
      "1786/1786 [==============================] - 0s 167us/step - loss: 0.2960 - acc: 0.8919\n",
      "Epoch 98/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.2959 - acc: 0.8925\n",
      "Epoch 99/100\n",
      "1786/1786 [==============================] - 0s 176us/step - loss: 0.2953 - acc: 0.8947\n",
      "Epoch 100/100\n",
      "1786/1786 [==============================] - 0s 170us/step - loss: 0.2947 - acc: 0.8959\n",
      "447/447 [==============================] - 1s 1ms/step\n",
      "Epoch 1/100\n",
      "1786/1786 [==============================] - 2s 986us/step - loss: 0.6649 - acc: 0.8421\n",
      "Epoch 2/100\n",
      "1786/1786 [==============================] - 0s 176us/step - loss: 0.6152 - acc: 0.8460\n",
      "Epoch 3/100\n",
      "1786/1786 [==============================] - 0s 169us/step - loss: 0.5693 - acc: 0.8572\n",
      "Epoch 4/100\n",
      "1786/1786 [==============================] - 0s 170us/step - loss: 0.5088 - acc: 0.8903\n",
      "Epoch 5/100\n",
      "1786/1786 [==============================] - 0s 167us/step - loss: 0.3486 - acc: 0.8959\n",
      "Epoch 6/100\n",
      "1786/1786 [==============================] - 0s 170us/step - loss: 0.2980 - acc: 0.8931\n",
      "Epoch 7/100\n",
      "1786/1786 [==============================] - 0s 167us/step - loss: 0.2850 - acc: 0.8992\n",
      "Epoch 8/100\n",
      "1786/1786 [==============================] - 0s 167us/step - loss: 0.2766 - acc: 0.8992\n",
      "Epoch 9/100\n",
      "1786/1786 [==============================] - 0s 175us/step - loss: 0.2719 - acc: 0.9015\n",
      "Epoch 10/100\n",
      "1786/1786 [==============================] - 0s 170us/step - loss: 0.2670 - acc: 0.9009\n",
      "Epoch 11/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.2633 - acc: 0.9020\n",
      "Epoch 12/100\n",
      "1786/1786 [==============================] - 0s 171us/step - loss: 0.2594 - acc: 0.9037\n",
      "Epoch 13/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.2569 - acc: 0.9043\n",
      "Epoch 14/100\n",
      "1786/1786 [==============================] - 0s 171us/step - loss: 0.2535 - acc: 0.9031\n",
      "Epoch 15/100\n",
      "1786/1786 [==============================] - 0s 169us/step - loss: 0.2512 - acc: 0.9020\n",
      "Epoch 16/100\n",
      "1786/1786 [==============================] - 0s 171us/step - loss: 0.2485 - acc: 0.9031\n",
      "Epoch 17/100\n",
      "1786/1786 [==============================] - 0s 169us/step - loss: 0.2461 - acc: 0.9037\n",
      "Epoch 18/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.2436 - acc: 0.9059\n",
      "Epoch 19/100\n",
      "1786/1786 [==============================] - 0s 173us/step - loss: 0.2412 - acc: 0.9059\n",
      "Epoch 20/100\n",
      "1786/1786 [==============================] - 0s 173us/step - loss: 0.2389 - acc: 0.9048\n",
      "Epoch 21/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.2364 - acc: 0.9059\n",
      "Epoch 22/100\n",
      "1786/1786 [==============================] - 0s 167us/step - loss: 0.2352 - acc: 0.9071\n",
      "Epoch 23/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.2324 - acc: 0.9043\n",
      "Epoch 24/100\n",
      "1786/1786 [==============================] - 0s 171us/step - loss: 0.2315 - acc: 0.9071\n",
      "Epoch 25/100\n",
      "1786/1786 [==============================] - 0s 171us/step - loss: 0.2299 - acc: 0.9059\n",
      "Epoch 26/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.2287 - acc: 0.9076\n",
      "Epoch 27/100\n",
      "1786/1786 [==============================] - 0s 176us/step - loss: 0.2268 - acc: 0.9076\n",
      "Epoch 28/100\n",
      "1786/1786 [==============================] - 0s 175us/step - loss: 0.2257 - acc: 0.9071\n",
      "Epoch 29/100\n",
      "1786/1786 [==============================] - 0s 174us/step - loss: 0.2239 - acc: 0.9082\n",
      "Epoch 30/100\n",
      "1786/1786 [==============================] - 0s 177us/step - loss: 0.2229 - acc: 0.9076\n",
      "Epoch 31/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.2212 - acc: 0.9093\n",
      "Epoch 32/100\n",
      "1786/1786 [==============================] - 0s 177us/step - loss: 0.2202 - acc: 0.9104\n",
      "Epoch 33/100\n",
      "1786/1786 [==============================] - 0s 175us/step - loss: 0.2204 - acc: 0.9059\n",
      "Epoch 34/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.2189 - acc: 0.9104\n",
      "Epoch 35/100\n",
      "1786/1786 [==============================] - 0s 171us/step - loss: 0.2182 - acc: 0.9082\n",
      "Epoch 36/100\n",
      "1786/1786 [==============================] - 0s 174us/step - loss: 0.2176 - acc: 0.9087\n",
      "Epoch 37/100\n",
      "1786/1786 [==============================] - 0s 175us/step - loss: 0.2163 - acc: 0.9087\n",
      "Epoch 38/100\n",
      "1786/1786 [==============================] - 0s 171us/step - loss: 0.2162 - acc: 0.9071\n",
      "Epoch 39/100\n",
      "1786/1786 [==============================] - 0s 175us/step - loss: 0.2157 - acc: 0.9087\n",
      "Epoch 40/100\n",
      "1786/1786 [==============================] - 0s 175us/step - loss: 0.2144 - acc: 0.9121\n",
      "Epoch 41/100\n",
      "1786/1786 [==============================] - 0s 175us/step - loss: 0.2130 - acc: 0.9099\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.2147 - acc: 0.9082\n",
      "Epoch 43/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.2127 - acc: 0.9110\n",
      "Epoch 44/100\n",
      "1786/1786 [==============================] - 0s 167us/step - loss: 0.2096 - acc: 0.9127\n",
      "Epoch 45/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.2113 - acc: 0.9104\n",
      "Epoch 46/100\n",
      "1786/1786 [==============================] - 0s 166us/step - loss: 0.2107 - acc: 0.9076\n",
      "Epoch 47/100\n",
      "1786/1786 [==============================] - 0s 170us/step - loss: 0.2116 - acc: 0.9099\n",
      "Epoch 48/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.2097 - acc: 0.9115\n",
      "Epoch 49/100\n",
      "1786/1786 [==============================] - 0s 170us/step - loss: 0.2085 - acc: 0.9166\n",
      "Epoch 50/100\n",
      "1786/1786 [==============================] - 0s 164us/step - loss: 0.2091 - acc: 0.9177\n",
      "Epoch 51/100\n",
      "1786/1786 [==============================] - 0s 165us/step - loss: 0.2074 - acc: 0.9205\n",
      "Epoch 52/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.2064 - acc: 0.9227\n",
      "Epoch 53/100\n",
      "1786/1786 [==============================] - 0s 166us/step - loss: 0.2070 - acc: 0.9222\n",
      "Epoch 54/100\n",
      "1786/1786 [==============================] - 0s 171us/step - loss: 0.2058 - acc: 0.9216\n",
      "Epoch 55/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.2055 - acc: 0.9216\n",
      "Epoch 56/100\n",
      "1786/1786 [==============================] - 0s 165us/step - loss: 0.2058 - acc: 0.9227\n",
      "Epoch 57/100\n",
      "1786/1786 [==============================] - 0s 166us/step - loss: 0.2037 - acc: 0.9244\n",
      "Epoch 58/100\n",
      "1786/1786 [==============================] - 0s 169us/step - loss: 0.2026 - acc: 0.9239\n",
      "Epoch 59/100\n",
      "1786/1786 [==============================] - 0s 183us/step - loss: 0.2035 - acc: 0.9244\n",
      "Epoch 60/100\n",
      "1786/1786 [==============================] - 0s 166us/step - loss: 0.2035 - acc: 0.9255\n",
      "Epoch 61/100\n",
      "1786/1786 [==============================] - 0s 169us/step - loss: 0.2027 - acc: 0.9267\n",
      "Epoch 62/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.2009 - acc: 0.9306\n",
      "Epoch 63/100\n",
      "1786/1786 [==============================] - 0s 171us/step - loss: 0.2020 - acc: 0.9261\n",
      "Epoch 64/100\n",
      "1786/1786 [==============================] - 0s 169us/step - loss: 0.2004 - acc: 0.9272\n",
      "Epoch 65/100\n",
      "1786/1786 [==============================] - 0s 169us/step - loss: 0.1997 - acc: 0.9300\n",
      "Epoch 66/100\n",
      "1786/1786 [==============================] - 0s 170us/step - loss: 0.2000 - acc: 0.9272 0s - loss: 0.2249 - acc: 0\n",
      "Epoch 67/100\n",
      "1786/1786 [==============================] - 0s 166us/step - loss: 0.1999 - acc: 0.9255\n",
      "Epoch 68/100\n",
      "1786/1786 [==============================] - 0s 169us/step - loss: 0.1977 - acc: 0.9289\n",
      "Epoch 69/100\n",
      "1786/1786 [==============================] - 0s 167us/step - loss: 0.1979 - acc: 0.9300\n",
      "Epoch 70/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.1979 - acc: 0.9311\n",
      "Epoch 71/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.1985 - acc: 0.9278\n",
      "Epoch 72/100\n",
      "1786/1786 [==============================] - 0s 170us/step - loss: 0.1966 - acc: 0.9339\n",
      "Epoch 73/100\n",
      "1786/1786 [==============================] - 0s 170us/step - loss: 0.1973 - acc: 0.9295\n",
      "Epoch 74/100\n",
      "1786/1786 [==============================] - 0s 167us/step - loss: 0.1954 - acc: 0.9300\n",
      "Epoch 75/100\n",
      "1786/1786 [==============================] - 0s 165us/step - loss: 0.1952 - acc: 0.9323\n",
      "Epoch 76/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.1955 - acc: 0.9317\n",
      "Epoch 77/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.1941 - acc: 0.9334\n",
      "Epoch 78/100\n",
      "1786/1786 [==============================] - 0s 165us/step - loss: 0.1946 - acc: 0.9328\n",
      "Epoch 79/100\n",
      "1786/1786 [==============================] - 0s 169us/step - loss: 0.1943 - acc: 0.9345\n",
      "Epoch 80/100\n",
      "1786/1786 [==============================] - 0s 166us/step - loss: 0.1929 - acc: 0.9328\n",
      "Epoch 81/100\n",
      "1786/1786 [==============================] - 0s 167us/step - loss: 0.1926 - acc: 0.9345\n",
      "Epoch 82/100\n",
      "1786/1786 [==============================] - 0s 167us/step - loss: 0.1905 - acc: 0.9345\n",
      "Epoch 83/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.1922 - acc: 0.9356\n",
      "Epoch 84/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.1917 - acc: 0.9356\n",
      "Epoch 85/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.1907 - acc: 0.9345\n",
      "Epoch 86/100\n",
      "1786/1786 [==============================] - 0s 165us/step - loss: 0.1911 - acc: 0.9345\n",
      "Epoch 87/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.1900 - acc: 0.9317\n",
      "Epoch 88/100\n",
      "1786/1786 [==============================] - 0s 170us/step - loss: 0.1907 - acc: 0.9334\n",
      "Epoch 89/100\n",
      "1786/1786 [==============================] - 0s 168us/step - loss: 0.1894 - acc: 0.9339\n",
      "Epoch 90/100\n",
      "1786/1786 [==============================] - 0s 166us/step - loss: 0.1881 - acc: 0.9362\n",
      "Epoch 91/100\n",
      "1786/1786 [==============================] - 0s 171us/step - loss: 0.1898 - acc: 0.9334\n",
      "Epoch 92/100\n",
      "1786/1786 [==============================] - 0s 175us/step - loss: 0.1876 - acc: 0.9362\n",
      "Epoch 93/100\n",
      "1786/1786 [==============================] - 0s 173us/step - loss: 0.1874 - acc: 0.9367\n",
      "Epoch 94/100\n",
      "1786/1786 [==============================] - 0s 170us/step - loss: 0.1882 - acc: 0.9367\n",
      "Epoch 95/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.1865 - acc: 0.9384\n",
      "Epoch 96/100\n",
      "1786/1786 [==============================] - 0s 169us/step - loss: 0.1861 - acc: 0.9356\n",
      "Epoch 97/100\n",
      "1786/1786 [==============================] - 0s 172us/step - loss: 0.1862 - acc: 0.9373\n",
      "Epoch 98/100\n",
      "1786/1786 [==============================] - 0s 170us/step - loss: 0.1850 - acc: 0.9390\n",
      "Epoch 99/100\n",
      "1786/1786 [==============================] - 0s 165us/step - loss: 0.1855 - acc: 0.9373\n",
      "Epoch 100/100\n",
      "1786/1786 [==============================] - 0s 171us/step - loss: 0.1836 - acc: 0.9395\n",
      "447/447 [==============================] - 1s 1ms/step\n",
      "Epoch 1/100\n",
      "1787/1787 [==============================] - 2s 1ms/step - loss: 0.6042 - acc: 0.8534\n",
      "Epoch 2/100\n",
      "1787/1787 [==============================] - 0s 166us/step - loss: 0.3649 - acc: 0.8551\n",
      "Epoch 3/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.3360 - acc: 0.8551\n",
      "Epoch 4/100\n",
      "1787/1787 [==============================] - 0s 176us/step - loss: 0.3289 - acc: 0.8551\n",
      "Epoch 5/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.3258 - acc: 0.8551\n",
      "Epoch 6/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3228 - acc: 0.8551\n",
      "Epoch 7/100\n",
      "1787/1787 [==============================] - 0s 175us/step - loss: 0.3212 - acc: 0.8551\n",
      "Epoch 8/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3199 - acc: 0.8551\n",
      "Epoch 9/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3191 - acc: 0.8623\n",
      "Epoch 10/100\n",
      "1787/1787 [==============================] - 0s 173us/step - loss: 0.3178 - acc: 0.8651\n",
      "Epoch 11/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.3173 - acc: 0.8674\n",
      "Epoch 12/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.3161 - acc: 0.8674\n",
      "Epoch 13/100\n",
      "1787/1787 [==============================] - 0s 165us/step - loss: 0.3152 - acc: 0.8685\n",
      "Epoch 14/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.3136 - acc: 0.8674\n",
      "Epoch 15/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3128 - acc: 0.8707\n",
      "Epoch 16/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.3126 - acc: 0.8730\n",
      "Epoch 17/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.3113 - acc: 0.8730\n",
      "Epoch 18/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.3108 - acc: 0.8735\n",
      "Epoch 19/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.3108 - acc: 0.8702\n",
      "Epoch 20/100\n",
      "1787/1787 [==============================] - 0s 174us/step - loss: 0.3096 - acc: 0.8730\n",
      "Epoch 21/100\n",
      "1787/1787 [==============================] - 0s 174us/step - loss: 0.3083 - acc: 0.8730\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1787/1787 [==============================] - 0s 161us/step - loss: 0.3083 - acc: 0.8724\n",
      "Epoch 23/100\n",
      "1787/1787 [==============================] - 0s 167us/step - loss: 0.3074 - acc: 0.8797\n",
      "Epoch 24/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3071 - acc: 0.8769\n",
      "Epoch 25/100\n",
      "1787/1787 [==============================] - 0s 167us/step - loss: 0.3073 - acc: 0.8769\n",
      "Epoch 26/100\n",
      "1787/1787 [==============================] - 0s 166us/step - loss: 0.3061 - acc: 0.8752\n",
      "Epoch 27/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.3064 - acc: 0.8780\n",
      "Epoch 28/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3057 - acc: 0.8769\n",
      "Epoch 29/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.3054 - acc: 0.8802\n",
      "Epoch 30/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.3047 - acc: 0.8791\n",
      "Epoch 31/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.3043 - acc: 0.8780\n",
      "Epoch 32/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.3042 - acc: 0.8786\n",
      "Epoch 33/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.3031 - acc: 0.8825\n",
      "Epoch 34/100\n",
      "1787/1787 [==============================] - 0s 167us/step - loss: 0.3026 - acc: 0.8802\n",
      "Epoch 35/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3025 - acc: 0.8797\n",
      "Epoch 36/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.3020 - acc: 0.8802\n",
      "Epoch 37/100\n",
      "1787/1787 [==============================] - 0s 167us/step - loss: 0.3016 - acc: 0.8825\n",
      "Epoch 38/100\n",
      "1787/1787 [==============================] - 0s 167us/step - loss: 0.3014 - acc: 0.8819\n",
      "Epoch 39/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3014 - acc: 0.8802\n",
      "Epoch 40/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.3001 - acc: 0.8802\n",
      "Epoch 41/100\n",
      "1787/1787 [==============================] - 0s 166us/step - loss: 0.3016 - acc: 0.8797\n",
      "Epoch 42/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.2994 - acc: 0.8819\n",
      "Epoch 43/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.2996 - acc: 0.8819\n",
      "Epoch 44/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.2987 - acc: 0.8819\n",
      "Epoch 45/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.2993 - acc: 0.8780\n",
      "Epoch 46/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2991 - acc: 0.8814\n",
      "Epoch 47/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.2984 - acc: 0.8847\n",
      "Epoch 48/100\n",
      "1787/1787 [==============================] - 0s 173us/step - loss: 0.2971 - acc: 0.8825\n",
      "Epoch 49/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.2978 - acc: 0.8825\n",
      "Epoch 50/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.2970 - acc: 0.8808\n",
      "Epoch 51/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.2973 - acc: 0.8836\n",
      "Epoch 52/100\n",
      "1787/1787 [==============================] - 0s 167us/step - loss: 0.2970 - acc: 0.8847\n",
      "Epoch 53/100\n",
      "1787/1787 [==============================] - 0s 167us/step - loss: 0.2964 - acc: 0.8836\n",
      "Epoch 54/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2965 - acc: 0.8842\n",
      "Epoch 55/100\n",
      "1787/1787 [==============================] - 0s 166us/step - loss: 0.2962 - acc: 0.8825\n",
      "Epoch 56/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2951 - acc: 0.8797\n",
      "Epoch 57/100\n",
      "1787/1787 [==============================] - 0s 177us/step - loss: 0.2960 - acc: 0.8808\n",
      "Epoch 58/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2953 - acc: 0.8819\n",
      "Epoch 59/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.2945 - acc: 0.8791\n",
      "Epoch 60/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.2944 - acc: 0.8830\n",
      "Epoch 61/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.2936 - acc: 0.8864\n",
      "Epoch 62/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.2937 - acc: 0.8814\n",
      "Epoch 63/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2939 - acc: 0.8842\n",
      "Epoch 64/100\n",
      "1787/1787 [==============================] - 0s 173us/step - loss: 0.2939 - acc: 0.8853\n",
      "Epoch 65/100\n",
      "1787/1787 [==============================] - 0s 167us/step - loss: 0.2928 - acc: 0.8819\n",
      "Epoch 66/100\n",
      "1787/1787 [==============================] - 0s 174us/step - loss: 0.2921 - acc: 0.8864\n",
      "Epoch 67/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.2920 - acc: 0.8836\n",
      "Epoch 68/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2917 - acc: 0.8819\n",
      "Epoch 69/100\n",
      "1787/1787 [==============================] - 0s 166us/step - loss: 0.2917 - acc: 0.8797\n",
      "Epoch 70/100\n",
      "1787/1787 [==============================] - 0s 173us/step - loss: 0.2911 - acc: 0.8836\n",
      "Epoch 71/100\n",
      "1787/1787 [==============================] - 0s 173us/step - loss: 0.2910 - acc: 0.8870\n",
      "Epoch 72/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2912 - acc: 0.8853\n",
      "Epoch 73/100\n",
      "1787/1787 [==============================] - 0s 176us/step - loss: 0.2912 - acc: 0.8836\n",
      "Epoch 74/100\n",
      "1787/1787 [==============================] - 0s 175us/step - loss: 0.2898 - acc: 0.8847\n",
      "Epoch 75/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2903 - acc: 0.8825\n",
      "Epoch 76/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.2902 - acc: 0.8836\n",
      "Epoch 77/100\n",
      "1787/1787 [==============================] - 0s 173us/step - loss: 0.2884 - acc: 0.8825\n",
      "Epoch 78/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.2896 - acc: 0.8825\n",
      "Epoch 79/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.2901 - acc: 0.8886\n",
      "Epoch 80/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2885 - acc: 0.8819\n",
      "Epoch 81/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.2888 - acc: 0.8825\n",
      "Epoch 82/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.2885 - acc: 0.8864\n",
      "Epoch 83/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2892 - acc: 0.8825\n",
      "Epoch 84/100\n",
      "1787/1787 [==============================] - 0s 174us/step - loss: 0.2883 - acc: 0.8870\n",
      "Epoch 85/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2886 - acc: 0.8853\n",
      "Epoch 86/100\n",
      "1787/1787 [==============================] - 0s 177us/step - loss: 0.2871 - acc: 0.8836\n",
      "Epoch 87/100\n",
      "1787/1787 [==============================] - 0s 173us/step - loss: 0.2884 - acc: 0.8870\n",
      "Epoch 88/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2872 - acc: 0.8802\n",
      "Epoch 89/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.2873 - acc: 0.8819\n",
      "Epoch 90/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2872 - acc: 0.8836\n",
      "Epoch 91/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.2871 - acc: 0.8814\n",
      "Epoch 92/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.2863 - acc: 0.8842\n",
      "Epoch 93/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.2855 - acc: 0.8836\n",
      "Epoch 94/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.2856 - acc: 0.8853\n",
      "Epoch 95/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.2848 - acc: 0.8842\n",
      "Epoch 96/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.2833 - acc: 0.8864\n",
      "Epoch 97/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2821 - acc: 0.8909\n",
      "Epoch 98/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.2817 - acc: 0.8892\n",
      "Epoch 99/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2801 - acc: 0.8914\n",
      "Epoch 100/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.2801 - acc: 0.8959\n",
      "446/446 [==============================] - 1s 1ms/step\n",
      "Epoch 1/100\n",
      "1787/1787 [==============================] - 2s 1ms/step - loss: 0.5724 - acc: 0.8483\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1787/1787 [==============================] - 0s 176us/step - loss: 0.3615 - acc: 0.8500\n",
      "Epoch 3/100\n",
      "1787/1787 [==============================] - 0s 175us/step - loss: 0.3450 - acc: 0.8500\n",
      "Epoch 4/100\n",
      "1787/1787 [==============================] - 0s 176us/step - loss: 0.3389 - acc: 0.8500\n",
      "Epoch 5/100\n",
      "1787/1787 [==============================] - 0s 174us/step - loss: 0.3347 - acc: 0.8500\n",
      "Epoch 6/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.3318 - acc: 0.8500\n",
      "Epoch 7/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3298 - acc: 0.8500\n",
      "Epoch 8/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.3287 - acc: 0.8500\n",
      "Epoch 9/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.3268 - acc: 0.8523\n",
      "Epoch 10/100\n",
      "1787/1787 [==============================] - 0s 167us/step - loss: 0.3262 - acc: 0.8607\n",
      "Epoch 11/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.3249 - acc: 0.8612\n",
      "Epoch 12/100\n",
      "1787/1787 [==============================] - 0s 175us/step - loss: 0.3245 - acc: 0.8595\n",
      "Epoch 13/100\n",
      "1787/1787 [==============================] - 0s 175us/step - loss: 0.3227 - acc: 0.8595\n",
      "Epoch 14/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.3230 - acc: 0.8623\n",
      "Epoch 15/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3217 - acc: 0.8679\n",
      "Epoch 16/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3211 - acc: 0.8601\n",
      "Epoch 17/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3205 - acc: 0.8657\n",
      "Epoch 18/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.3194 - acc: 0.8674\n",
      "Epoch 19/100\n",
      "1787/1787 [==============================] - 0s 167us/step - loss: 0.3194 - acc: 0.8663\n",
      "Epoch 20/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.3175 - acc: 0.8696\n",
      "Epoch 21/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3170 - acc: 0.8713\n",
      "Epoch 22/100\n",
      "1787/1787 [==============================] - 0s 167us/step - loss: 0.3163 - acc: 0.8679\n",
      "Epoch 23/100\n",
      "1787/1787 [==============================] - 0s 174us/step - loss: 0.3158 - acc: 0.8663\n",
      "Epoch 24/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3152 - acc: 0.8679\n",
      "Epoch 25/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3141 - acc: 0.8685\n",
      "Epoch 26/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.3131 - acc: 0.8685\n",
      "Epoch 27/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.3113 - acc: 0.8730\n",
      "Epoch 28/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.3108 - acc: 0.8685\n",
      "Epoch 29/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.3096 - acc: 0.8730\n",
      "Epoch 30/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.3087 - acc: 0.8769\n",
      "Epoch 31/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.3076 - acc: 0.8758\n",
      "Epoch 32/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.3063 - acc: 0.8786\n",
      "Epoch 33/100\n",
      "1787/1787 [==============================] - 0s 180us/step - loss: 0.3046 - acc: 0.8780 0s - loss: 0.3368 - acc: \n",
      "Epoch 34/100\n",
      "1787/1787 [==============================] - 0s 175us/step - loss: 0.3029 - acc: 0.8808\n",
      "Epoch 35/100\n",
      "1787/1787 [==============================] - 0s 176us/step - loss: 0.3004 - acc: 0.8819\n",
      "Epoch 36/100\n",
      "1787/1787 [==============================] - 0s 175us/step - loss: 0.2994 - acc: 0.8825\n",
      "Epoch 37/100\n",
      "1787/1787 [==============================] - 0s 174us/step - loss: 0.2961 - acc: 0.8814\n",
      "Epoch 38/100\n",
      "1787/1787 [==============================] - 0s 174us/step - loss: 0.2937 - acc: 0.8881\n",
      "Epoch 39/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.2894 - acc: 0.8909\n",
      "Epoch 40/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.2806 - acc: 0.8976\n",
      "Epoch 41/100\n",
      "1787/1787 [==============================] - 0s 173us/step - loss: 0.2742 - acc: 0.8959\n",
      "Epoch 42/100\n",
      "1787/1787 [==============================] - 0s 173us/step - loss: 0.2679 - acc: 0.8993\n",
      "Epoch 43/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.2620 - acc: 0.9043\n",
      "Epoch 44/100\n",
      "1787/1787 [==============================] - 0s 174us/step - loss: 0.2567 - acc: 0.9021\n",
      "Epoch 45/100\n",
      "1787/1787 [==============================] - 0s 174us/step - loss: 0.2525 - acc: 0.9082\n",
      "Epoch 46/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.2471 - acc: 0.9082\n",
      "Epoch 47/100\n",
      "1787/1787 [==============================] - 0s 174us/step - loss: 0.2428 - acc: 0.9093\n",
      "Epoch 48/100\n",
      "1787/1787 [==============================] - 0s 177us/step - loss: 0.2405 - acc: 0.9105\n",
      "Epoch 49/100\n",
      "1787/1787 [==============================] - 0s 174us/step - loss: 0.2381 - acc: 0.9121\n",
      "Epoch 50/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.2330 - acc: 0.9116\n",
      "Epoch 51/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2293 - acc: 0.9110\n",
      "Epoch 52/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.2278 - acc: 0.9138\n",
      "Epoch 53/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.2254 - acc: 0.9161\n",
      "Epoch 54/100\n",
      "1787/1787 [==============================] - 0s 173us/step - loss: 0.2237 - acc: 0.9177\n",
      "Epoch 55/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.2210 - acc: 0.9189\n",
      "Epoch 56/100\n",
      "1787/1787 [==============================] - 0s 174us/step - loss: 0.2198 - acc: 0.9194\n",
      "Epoch 57/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.2169 - acc: 0.9233\n",
      "Epoch 58/100\n",
      "1787/1787 [==============================] - 0s 173us/step - loss: 0.2161 - acc: 0.9217\n",
      "Epoch 59/100\n",
      "1787/1787 [==============================] - 0s 177us/step - loss: 0.2153 - acc: 0.9273\n",
      "Epoch 60/100\n",
      "1787/1787 [==============================] - 0s 178us/step - loss: 0.2135 - acc: 0.9273\n",
      "Epoch 61/100\n",
      "1787/1787 [==============================] - 0s 176us/step - loss: 0.2121 - acc: 0.9250\n",
      "Epoch 62/100\n",
      "1787/1787 [==============================] - 0s 178us/step - loss: 0.2114 - acc: 0.9284\n",
      "Epoch 63/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.2104 - acc: 0.9256\n",
      "Epoch 64/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.2077 - acc: 0.9289\n",
      "Epoch 65/100\n",
      "1787/1787 [==============================] - 0s 171us/step - loss: 0.2088 - acc: 0.9317\n",
      "Epoch 66/100\n",
      "1787/1787 [==============================] - 0s 175us/step - loss: 0.2077 - acc: 0.9289\n",
      "Epoch 67/100\n",
      "1787/1787 [==============================] - 0s 175us/step - loss: 0.2070 - acc: 0.9284\n",
      "Epoch 68/100\n",
      "1787/1787 [==============================] - 0s 170us/step - loss: 0.2058 - acc: 0.9351\n",
      "Epoch 69/100\n",
      "1787/1787 [==============================] - 0s 175us/step - loss: 0.2050 - acc: 0.9334\n",
      "Epoch 70/100\n",
      "1787/1787 [==============================] - 0s 177us/step - loss: 0.2045 - acc: 0.9323\n",
      "Epoch 71/100\n",
      "1787/1787 [==============================] - 0s 181us/step - loss: 0.2047 - acc: 0.9317\n",
      "Epoch 72/100\n",
      "1787/1787 [==============================] - 0s 179us/step - loss: 0.2035 - acc: 0.9345\n",
      "Epoch 73/100\n",
      "1787/1787 [==============================] - 0s 178us/step - loss: 0.2026 - acc: 0.9334\n",
      "Epoch 74/100\n",
      "1787/1787 [==============================] - 0s 175us/step - loss: 0.2029 - acc: 0.9334\n",
      "Epoch 75/100\n",
      "1787/1787 [==============================] - 0s 178us/step - loss: 0.2008 - acc: 0.9356\n",
      "Epoch 76/100\n",
      "1787/1787 [==============================] - 0s 173us/step - loss: 0.2003 - acc: 0.9340\n",
      "Epoch 77/100\n",
      "1787/1787 [==============================] - 0s 178us/step - loss: 0.1987 - acc: 0.9351\n",
      "Epoch 78/100\n",
      "1787/1787 [==============================] - 0s 182us/step - loss: 0.2005 - acc: 0.9351\n",
      "Epoch 79/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.1973 - acc: 0.9351\n",
      "Epoch 80/100\n",
      "1787/1787 [==============================] - 0s 176us/step - loss: 0.1990 - acc: 0.9362\n",
      "Epoch 81/100\n",
      "1787/1787 [==============================] - 0s 176us/step - loss: 0.1971 - acc: 0.9390\n",
      "Epoch 82/100\n",
      "1787/1787 [==============================] - 0s 182us/step - loss: 0.1968 - acc: 0.9390\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1787/1787 [==============================] - 0s 175us/step - loss: 0.1970 - acc: 0.9373\n",
      "Epoch 84/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.1966 - acc: 0.9368\n",
      "Epoch 85/100\n",
      "1787/1787 [==============================] - 0s 175us/step - loss: 0.1951 - acc: 0.9390\n",
      "Epoch 86/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.1955 - acc: 0.9362\n",
      "Epoch 87/100\n",
      "1787/1787 [==============================] - 0s 168us/step - loss: 0.1943 - acc: 0.9401\n",
      "Epoch 88/100\n",
      "1787/1787 [==============================] - 0s 172us/step - loss: 0.1944 - acc: 0.9407\n",
      "Epoch 89/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.1945 - acc: 0.9396\n",
      "Epoch 90/100\n",
      "1787/1787 [==============================] - 0s 167us/step - loss: 0.1928 - acc: 0.9412\n",
      "Epoch 91/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.1954 - acc: 0.9390\n",
      "Epoch 92/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.1934 - acc: 0.9407\n",
      "Epoch 93/100\n",
      "1787/1787 [==============================] - 0s 176us/step - loss: 0.1928 - acc: 0.9396\n",
      "Epoch 94/100\n",
      "1787/1787 [==============================] - 0s 169us/step - loss: 0.1940 - acc: 0.9418\n",
      "Epoch 95/100\n",
      "1787/1787 [==============================] - 0s 167us/step - loss: 0.1918 - acc: 0.9412\n",
      "Epoch 96/100\n",
      "1787/1787 [==============================] - 0s 173us/step - loss: 0.1925 - acc: 0.9412\n",
      "Epoch 97/100\n",
      "1787/1787 [==============================] - 0s 177us/step - loss: 0.1922 - acc: 0.9446\n",
      "Epoch 98/100\n",
      "1787/1787 [==============================] - 0s 174us/step - loss: 0.1917 - acc: 0.9418\n",
      "Epoch 99/100\n",
      "1787/1787 [==============================] - 0s 173us/step - loss: 0.1924 - acc: 0.9384\n",
      "Epoch 100/100\n",
      "1787/1787 [==============================] - 0s 176us/step - loss: 0.1915 - acc: 0.9407\n",
      "446/446 [==============================] - 1s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "classifier = KerasClassifier(build_fn = buildClassifier, batch_size = 10, epochs = 100, optimizer = 'adam')\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 5)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91498881, 0.86800895, 0.91275167, 0.87443945, 0.91704035])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8974458455681852"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.021548982525618206"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildClassifierWithDropout(optimizer):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu', input_dim = 16))\n",
    "    classifier.add(Dropout(rate=0.1))\n",
    "    classifier.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'relu'))\n",
    "    classifier.add(Dropout(rate=0.1))\n",
    "    classifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "    classifier.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(build_fn = buildClassifierWithDropout, batch_size = 10, epochs = 100, verbose = 0, optimizer='adam' )\n",
    "accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 5)\n",
    "mean = accuracies.mean()\n",
    "variance = accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85458612, 0.8836689 , 0.87024608, 0.88340807, 0.867713  ])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8719244325015438"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.010871765365516407"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1786/1786 [==============================] - 2s 978us/step - loss: 0.5657 - acc: 0.8527\n",
      "Epoch 2/100\n",
      "1786/1786 [==============================] - 0s 184us/step - loss: 0.3611 - acc: 0.8527\n",
      "Epoch 3/100\n",
      "1786/1786 [==============================] - 0s 184us/step - loss: 0.3446 - acc: 0.8527\n",
      "Epoch 4/100\n",
      "1786/1786 [==============================] - 0s 185us/step - loss: 0.3355 - acc: 0.8527\n",
      "Epoch 5/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3387 - acc: 0.8527\n",
      "Epoch 6/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3337 - acc: 0.8527\n",
      "Epoch 7/100\n",
      "1786/1786 [==============================] - 0s 185us/step - loss: 0.3321 - acc: 0.8527\n",
      "Epoch 8/100\n",
      "1786/1786 [==============================] - 0s 182us/step - loss: 0.3317 - acc: 0.8527\n",
      "Epoch 9/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3284 - acc: 0.8527\n",
      "Epoch 10/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3271 - acc: 0.8527\n",
      "Epoch 11/100\n",
      "1786/1786 [==============================] - 0s 193us/step - loss: 0.3269 - acc: 0.8527\n",
      "Epoch 12/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3231 - acc: 0.8527\n",
      "Epoch 13/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3243 - acc: 0.8527\n",
      "Epoch 14/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3240 - acc: 0.8527\n",
      "Epoch 15/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3253 - acc: 0.8527\n",
      "Epoch 16/100\n",
      "1786/1786 [==============================] - 0s 186us/step - loss: 0.3247 - acc: 0.8522\n",
      "Epoch 17/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3230 - acc: 0.8639\n",
      "Epoch 18/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3218 - acc: 0.8679\n",
      "Epoch 19/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3228 - acc: 0.8695\n",
      "Epoch 20/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3229 - acc: 0.8695\n",
      "Epoch 21/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3186 - acc: 0.8723\n",
      "Epoch 22/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3208 - acc: 0.8707\n",
      "Epoch 23/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3181 - acc: 0.8690\n",
      "Epoch 24/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3203 - acc: 0.8679\n",
      "Epoch 25/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3205 - acc: 0.8729\n",
      "Epoch 26/100\n",
      "1786/1786 [==============================] - 0s 196us/step - loss: 0.3223 - acc: 0.8701\n",
      "Epoch 27/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3215 - acc: 0.8701\n",
      "Epoch 28/100\n",
      "1786/1786 [==============================] - 0s 186us/step - loss: 0.3154 - acc: 0.8712\n",
      "Epoch 29/100\n",
      "1786/1786 [==============================] - 0s 186us/step - loss: 0.3236 - acc: 0.8751\n",
      "Epoch 30/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3169 - acc: 0.8718\n",
      "Epoch 31/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3184 - acc: 0.8740\n",
      "Epoch 32/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3147 - acc: 0.8751\n",
      "Epoch 33/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3178 - acc: 0.8774\n",
      "Epoch 34/100\n",
      "1786/1786 [==============================] - 0s 186us/step - loss: 0.3134 - acc: 0.8779\n",
      "Epoch 35/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3148 - acc: 0.8735\n",
      "Epoch 36/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3203 - acc: 0.8735\n",
      "Epoch 37/100\n",
      "1786/1786 [==============================] - 0s 184us/step - loss: 0.3162 - acc: 0.8740\n",
      "Epoch 38/100\n",
      "1786/1786 [==============================] - 0s 194us/step - loss: 0.3146 - acc: 0.8701\n",
      "Epoch 39/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3163 - acc: 0.8774\n",
      "Epoch 40/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3181 - acc: 0.8751\n",
      "Epoch 41/100\n",
      "1786/1786 [==============================] - 0s 195us/step - loss: 0.3217 - acc: 0.8718\n",
      "Epoch 42/100\n",
      "1786/1786 [==============================] - 0s 195us/step - loss: 0.3136 - acc: 0.8723\n",
      "Epoch 43/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3091 - acc: 0.8757\n",
      "Epoch 44/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3182 - acc: 0.8673\n",
      "Epoch 45/100\n",
      "1786/1786 [==============================] - 0s 184us/step - loss: 0.3150 - acc: 0.8774\n",
      "Epoch 46/100\n",
      "1786/1786 [==============================] - 0s 193us/step - loss: 0.3186 - acc: 0.8757\n",
      "Epoch 47/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3148 - acc: 0.8740\n",
      "Epoch 48/100\n",
      "1786/1786 [==============================] - 0s 183us/step - loss: 0.3190 - acc: 0.8757\n",
      "Epoch 49/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3103 - acc: 0.8729\n",
      "Epoch 50/100\n",
      "1786/1786 [==============================] - 0s 181us/step - loss: 0.3151 - acc: 0.8751\n",
      "Epoch 51/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3144 - acc: 0.8746\n",
      "Epoch 52/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3190 - acc: 0.8740\n",
      "Epoch 53/100\n",
      "1786/1786 [==============================] - 0s 199us/step - loss: 0.3145 - acc: 0.8746\n",
      "Epoch 54/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3172 - acc: 0.8768\n",
      "Epoch 55/100\n",
      "1786/1786 [==============================] - 0s 195us/step - loss: 0.3137 - acc: 0.8718\n",
      "Epoch 56/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3154 - acc: 0.8796\n",
      "Epoch 57/100\n",
      "1786/1786 [==============================] - 0s 194us/step - loss: 0.3150 - acc: 0.8729\n",
      "Epoch 58/100\n",
      "1786/1786 [==============================] - 0s 198us/step - loss: 0.3152 - acc: 0.8757\n",
      "Epoch 59/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3179 - acc: 0.8763\n",
      "Epoch 60/100\n",
      "1786/1786 [==============================] - 0s 197us/step - loss: 0.3138 - acc: 0.8723\n",
      "Epoch 61/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3176 - acc: 0.8785\n",
      "Epoch 62/100\n",
      "1786/1786 [==============================] - 0s 186us/step - loss: 0.3151 - acc: 0.8735\n",
      "Epoch 63/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3144 - acc: 0.8712\n",
      "Epoch 64/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3159 - acc: 0.8735\n",
      "Epoch 65/100\n",
      "1786/1786 [==============================] - 0s 194us/step - loss: 0.3065 - acc: 0.8763\n",
      "Epoch 66/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3142 - acc: 0.8757\n",
      "Epoch 67/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3170 - acc: 0.8796\n",
      "Epoch 68/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3103 - acc: 0.8740\n",
      "Epoch 69/100\n",
      "1786/1786 [==============================] - 0s 197us/step - loss: 0.3177 - acc: 0.8718\n",
      "Epoch 70/100\n",
      "1786/1786 [==============================] - 0s 195us/step - loss: 0.3160 - acc: 0.8757\n",
      "Epoch 71/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3119 - acc: 0.8729\n",
      "Epoch 72/100\n",
      "1786/1786 [==============================] - 0s 193us/step - loss: 0.3104 - acc: 0.8774\n",
      "Epoch 73/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3086 - acc: 0.8791\n",
      "Epoch 74/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3139 - acc: 0.8712\n",
      "Epoch 75/100\n",
      "1786/1786 [==============================] - 0s 186us/step - loss: 0.3158 - acc: 0.8763\n",
      "Epoch 76/100\n",
      "1786/1786 [==============================] - 0s 194us/step - loss: 0.3156 - acc: 0.8695\n",
      "Epoch 77/100\n",
      "1786/1786 [==============================] - 0s 182us/step - loss: 0.3079 - acc: 0.8757\n",
      "Epoch 78/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3151 - acc: 0.8740\n",
      "Epoch 79/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3140 - acc: 0.8763\n",
      "Epoch 80/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3142 - acc: 0.8763\n",
      "Epoch 81/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3154 - acc: 0.8723\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3111 - acc: 0.8746\n",
      "Epoch 83/100\n",
      "1786/1786 [==============================] - 0s 184us/step - loss: 0.3152 - acc: 0.8718\n",
      "Epoch 84/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3167 - acc: 0.8729\n",
      "Epoch 85/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3146 - acc: 0.8740\n",
      "Epoch 86/100\n",
      "1786/1786 [==============================] - 0s 194us/step - loss: 0.3111 - acc: 0.8774\n",
      "Epoch 87/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3087 - acc: 0.8768\n",
      "Epoch 88/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3075 - acc: 0.8746\n",
      "Epoch 89/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3144 - acc: 0.8746\n",
      "Epoch 90/100\n",
      "1786/1786 [==============================] - 0s 185us/step - loss: 0.3197 - acc: 0.8768\n",
      "Epoch 91/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3150 - acc: 0.8785\n",
      "Epoch 92/100\n",
      "1786/1786 [==============================] - 0s 197us/step - loss: 0.3110 - acc: 0.8807\n",
      "Epoch 93/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3161 - acc: 0.8751\n",
      "Epoch 94/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3132 - acc: 0.8746\n",
      "Epoch 95/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3192 - acc: 0.8746\n",
      "Epoch 96/100\n",
      "1786/1786 [==============================] - 0s 183us/step - loss: 0.3150 - acc: 0.8785\n",
      "Epoch 97/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3104 - acc: 0.8746\n",
      "Epoch 98/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3089 - acc: 0.8785\n",
      "Epoch 99/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3122 - acc: 0.8735\n",
      "Epoch 100/100\n",
      "1786/1786 [==============================] - 0s 185us/step - loss: 0.3192 - acc: 0.8729\n",
      "Epoch 1/100\n",
      "1786/1786 [==============================] - 2s 1ms/step - loss: 0.5731 - acc: 0.8483\n",
      "Epoch 2/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3640 - acc: 0.8505\n",
      "Epoch 3/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3539 - acc: 0.8505 0s - loss: 0.3524 - acc: 0.851\n",
      "Epoch 4/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3443 - acc: 0.8505\n",
      "Epoch 5/100\n",
      "1786/1786 [==============================] - 0s 197us/step - loss: 0.3377 - acc: 0.8505\n",
      "Epoch 6/100\n",
      "1786/1786 [==============================] - 0s 185us/step - loss: 0.3372 - acc: 0.8505\n",
      "Epoch 7/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3398 - acc: 0.8505\n",
      "Epoch 8/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3352 - acc: 0.8505\n",
      "Epoch 9/100\n",
      "1786/1786 [==============================] - 0s 185us/step - loss: 0.3345 - acc: 0.8505\n",
      "Epoch 10/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3367 - acc: 0.8505\n",
      "Epoch 11/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3370 - acc: 0.8505\n",
      "Epoch 12/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3323 - acc: 0.8505\n",
      "Epoch 13/100\n",
      "1786/1786 [==============================] - 0s 185us/step - loss: 0.3316 - acc: 0.8505\n",
      "Epoch 14/100\n",
      "1786/1786 [==============================] - 0s 185us/step - loss: 0.3334 - acc: 0.8505\n",
      "Epoch 15/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3335 - acc: 0.8505\n",
      "Epoch 16/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3322 - acc: 0.8505\n",
      "Epoch 17/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3338 - acc: 0.8505\n",
      "Epoch 18/100\n",
      "1786/1786 [==============================] - 0s 186us/step - loss: 0.3288 - acc: 0.8505 0s - loss: 0.3297 - acc: 0.848\n",
      "Epoch 19/100\n",
      "1786/1786 [==============================] - 0s 183us/step - loss: 0.3317 - acc: 0.8505\n",
      "Epoch 20/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3300 - acc: 0.8505\n",
      "Epoch 21/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3286 - acc: 0.8511\n",
      "Epoch 22/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3310 - acc: 0.8544\n",
      "Epoch 23/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3276 - acc: 0.8578 0s - loss: 0.3260 - acc: 0.860\n",
      "Epoch 24/100\n",
      "1786/1786 [==============================] - 0s 182us/step - loss: 0.3278 - acc: 0.8595\n",
      "Epoch 25/100\n",
      "1786/1786 [==============================] - 0s 179us/step - loss: 0.3275 - acc: 0.8617\n",
      "Epoch 26/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3249 - acc: 0.8656\n",
      "Epoch 27/100\n",
      "1786/1786 [==============================] - 0s 185us/step - loss: 0.3235 - acc: 0.8656\n",
      "Epoch 28/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3254 - acc: 0.8639\n",
      "Epoch 29/100\n",
      "1786/1786 [==============================] - 0s 186us/step - loss: 0.3234 - acc: 0.8690\n",
      "Epoch 30/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3248 - acc: 0.8667\n",
      "Epoch 31/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3220 - acc: 0.8701\n",
      "Epoch 32/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3242 - acc: 0.8679\n",
      "Epoch 33/100\n",
      "1786/1786 [==============================] - 0s 191us/step - loss: 0.3290 - acc: 0.8667\n",
      "Epoch 34/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3266 - acc: 0.8667\n",
      "Epoch 35/100\n",
      "1786/1786 [==============================] - 0s 184us/step - loss: 0.3184 - acc: 0.8712\n",
      "Epoch 36/100\n",
      "1786/1786 [==============================] - 0s 183us/step - loss: 0.3282 - acc: 0.8695\n",
      "Epoch 37/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3269 - acc: 0.8695\n",
      "Epoch 38/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3257 - acc: 0.8667\n",
      "Epoch 39/100\n",
      "1786/1786 [==============================] - 0s 183us/step - loss: 0.3259 - acc: 0.8712\n",
      "Epoch 40/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3299 - acc: 0.8673\n",
      "Epoch 41/100\n",
      "1786/1786 [==============================] - 0s 186us/step - loss: 0.3248 - acc: 0.8617\n",
      "Epoch 42/100\n",
      "1786/1786 [==============================] - 0s 190us/step - loss: 0.3275 - acc: 0.8673\n",
      "Epoch 43/100\n",
      "1786/1786 [==============================] - 0s 187us/step - loss: 0.3271 - acc: 0.8707\n",
      "Epoch 44/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3284 - acc: 0.8656\n",
      "Epoch 45/100\n",
      "1786/1786 [==============================] - 0s 184us/step - loss: 0.3227 - acc: 0.8679\n",
      "Epoch 46/100\n",
      "1786/1786 [==============================] - 0s 184us/step - loss: 0.3270 - acc: 0.8684\n",
      "Epoch 47/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3246 - acc: 0.8684\n",
      "Epoch 48/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3230 - acc: 0.8684\n",
      "Epoch 49/100\n",
      "1786/1786 [==============================] - 0s 185us/step - loss: 0.3200 - acc: 0.8718\n",
      "Epoch 50/100\n",
      "1786/1786 [==============================] - 0s 186us/step - loss: 0.3232 - acc: 0.8712\n",
      "Epoch 51/100\n",
      "1786/1786 [==============================] - 0s 189us/step - loss: 0.3143 - acc: 0.8701\n",
      "Epoch 52/100\n",
      "1786/1786 [==============================] - 0s 186us/step - loss: 0.3259 - acc: 0.8701\n",
      "Epoch 53/100\n",
      "1786/1786 [==============================] - 0s 195us/step - loss: 0.3214 - acc: 0.8701\n",
      "Epoch 54/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3206 - acc: 0.8735\n",
      "Epoch 55/100\n",
      "1786/1786 [==============================] - 0s 193us/step - loss: 0.3244 - acc: 0.8723\n",
      "Epoch 56/100\n",
      "1786/1786 [==============================] - 0s 196us/step - loss: 0.3205 - acc: 0.8684\n",
      "Epoch 57/100\n",
      "1786/1786 [==============================] - 0s 196us/step - loss: 0.3225 - acc: 0.8757\n",
      "Epoch 58/100\n",
      "1786/1786 [==============================] - 0s 203us/step - loss: 0.3161 - acc: 0.8740\n",
      "Epoch 59/100\n",
      "1786/1786 [==============================] - 0s 203us/step - loss: 0.3212 - acc: 0.8757\n",
      "Epoch 60/100\n",
      "1786/1786 [==============================] - 0s 211us/step - loss: 0.3219 - acc: 0.8729\n",
      "Epoch 61/100\n",
      "1786/1786 [==============================] - 0s 213us/step - loss: 0.3210 - acc: 0.8718\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1786/1786 [==============================] - 0s 209us/step - loss: 0.3183 - acc: 0.8735\n",
      "Epoch 63/100\n",
      "1786/1786 [==============================] - 0s 201us/step - loss: 0.3159 - acc: 0.8763\n",
      "Epoch 64/100\n",
      "1786/1786 [==============================] - 0s 194us/step - loss: 0.3197 - acc: 0.8746\n",
      "Epoch 65/100\n",
      "1786/1786 [==============================] - 0s 202us/step - loss: 0.3182 - acc: 0.8785\n",
      "Epoch 66/100\n",
      "1786/1786 [==============================] - 0s 192us/step - loss: 0.3157 - acc: 0.8757\n",
      "Epoch 67/100\n",
      "1786/1786 [==============================] - 0s 199us/step - loss: 0.3160 - acc: 0.8779\n",
      "Epoch 68/100\n",
      "1786/1786 [==============================] - 0s 213us/step - loss: 0.3201 - acc: 0.8746\n",
      "Epoch 69/100\n",
      "1786/1786 [==============================] - 0s 207us/step - loss: 0.3116 - acc: 0.8690\n",
      "Epoch 70/100\n",
      "1786/1786 [==============================] - 0s 201us/step - loss: 0.3207 - acc: 0.8718\n",
      "Epoch 71/100\n",
      "1786/1786 [==============================] - 0s 199us/step - loss: 0.3221 - acc: 0.8802\n",
      "Epoch 72/100\n",
      "1786/1786 [==============================] - 0s 196us/step - loss: 0.3243 - acc: 0.8729\n",
      "Epoch 73/100\n",
      "1786/1786 [==============================] - 0s 202us/step - loss: 0.3231 - acc: 0.8768\n",
      "Epoch 74/100\n",
      "1786/1786 [==============================] - 0s 194us/step - loss: 0.3131 - acc: 0.8791\n",
      "Epoch 75/100\n",
      "1786/1786 [==============================] - 0s 188us/step - loss: 0.3129 - acc: 0.8785\n",
      "Epoch 76/100\n",
      "1786/1786 [==============================] - 0s 196us/step - loss: 0.3207 - acc: 0.8779\n",
      "Epoch 77/100\n",
      "1100/1786 [=================>............] - ETA: 0s - loss: 0.3094 - acc: 0.8809"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-e299f00c729e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m                            \u001b[0mscoring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                            cv = 5)\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mbest_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mbest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2355\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2356\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2357\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.2/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "classifier = KerasClassifier(build_fn = buildClassifierWithDropout, epochs = 100)\n",
    "parameters = {'batch_size': [10, 15],\n",
    "              'optimizer': ['adam', 'rmsprop']}\n",
    "grid_search = GridSearchCV(estimator = classifier,\n",
    "                           param_grid = parameters,\n",
    "                           scoring = 'accuracy',\n",
    "                           cv = 5)\n",
    "grid_search     = grid_search.fit(x_train, y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy   = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
