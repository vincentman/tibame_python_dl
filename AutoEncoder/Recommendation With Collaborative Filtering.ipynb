{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from zipfile import ZipFile\n",
    "\n",
    "def load_data():\n",
    "    path = get_file('ml-100k.zip', origin='http://files.grouplens.org/datasets/movielens/ml-100k.zip')\n",
    "    with ZipFile(path, 'r') as ml_zip:\n",
    "        max_item_id  = -1\n",
    "        train_history = {}\n",
    "        with ml_zip.open('ml-100k/ua.base', 'r') as file:\n",
    "            for line in file:\n",
    "                user_id, item_id, rating, timestamp = line.decode('utf-8').rstrip().split('\\t')\n",
    "                if int(user_id) not in train_history:\n",
    "                    train_history[int(user_id)] = [int(item_id)]\n",
    "                else:\n",
    "                    train_history[int(user_id)].append(int(item_id))\n",
    "\n",
    "                if max_item_id < int(item_id):\n",
    "                    max_item_id = int(item_id)\n",
    "\n",
    "        test_history = {}\n",
    "        with ml_zip.open('ml-100k/ua.test', 'r') as file:\n",
    "            for line in file:\n",
    "                user_id, item_id, rating, timestamp = line.decode('utf-8').rstrip().split('\\t')\n",
    "                if int(user_id) not in test_history:\n",
    "                    test_history[int(user_id)] = [int(item_id)]\n",
    "                else:\n",
    "                    test_history[int(user_id)].append(int(item_id))\n",
    "\n",
    "    max_item_id += 1 # item_id starts from 1\n",
    "    train_users = list(train_history.keys())\n",
    "    train_x = numpy.zeros((len(train_users), max_item_id), dtype=numpy.int32)\n",
    "    for i, hist in enumerate(train_history.values()):\n",
    "        mat = to_categorical(hist, max_item_id)\n",
    "        train_x[i] = numpy.sum(mat, axis=0)\n",
    "\n",
    "    test_users = list(test_history.keys())\n",
    "    test_x = numpy.zeros((len(test_users), max_item_id), dtype=numpy.int32)\n",
    "    for i, hist in enumerate(test_history.values()):\n",
    "        mat = to_categorical(hist, max_item_id)\n",
    "        test_x[i] = numpy.sum(mat, axis=0)\n",
    "\n",
    "    return train_users, train_x, test_users, test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def success_rate(pred, true):\n",
    "    cnt = 0\n",
    "    for i in range(pred.shape[0]):\n",
    "        t = numpy.where(true[i] == 1) # true set\n",
    "        ary = numpy.intersect1d(pred[i], t)\n",
    "        if ary.size > 0:\n",
    "            cnt += 1\n",
    "    return cnt * 100 / pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense, Embedding, Flatten, Dropout, merge, Activation\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def CDAE(I, U, K, hidden_activation, output_activation, q=0.5, l=0.01):\n",
    "    x_item = Input((I,), name='x_item')\n",
    "    h_item = Dropout(q)(x_item)\n",
    "    h_item = Dense(K, W_regularizer=l2(l), b_regularizer=l2(l))(h_item)\n",
    "\n",
    "    x_user = Input((1,), dtype='int32', name='x_user')\n",
    "    h_user = Embedding(input_dim=U, output_dim=K, input_length=1, W_regularizer=l2(l))(x_user)\n",
    "    h_user = Flatten()(h_user)\n",
    "\n",
    "    h = merge([h_item, h_user], mode='sum')\n",
    "    if hidden_activation:\n",
    "        h = Activation(hidden_activation)(h)\n",
    "    y = Dense(I, activation=output_activation)(h)\n",
    "\n",
    "    return Model(input=[x_item, x_user], output=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(50, kernel_regularizer=<keras.reg..., bias_regularizer=<keras.reg...)`\n",
      "  \n",
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: Update your `Embedding` call to the Keras 2 API: `Embedding(input_dim=944, output_dim=50, input_length=1, embeddings_regularizer=<keras.reg...)`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  \n",
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/keras/legacy/layers.py:458: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "/Users/davidchiu/.pyenv/versions/3.6.2/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.random.seed(0)\n",
    "\n",
    "\n",
    "# data\n",
    "train_users, train_x, test_users, test_x = load_data()\n",
    "train_x_users = numpy.array(train_users, dtype=numpy.int32).reshape(len(train_users), 1)\n",
    "test_x_users = numpy.array(test_users, dtype=numpy.int32).reshape(len(test_users), 1)\n",
    "\n",
    "# model\n",
    "model = CDAE(I=train_x.shape[1], U=len(train_users)+1, K=50,\n",
    "                    hidden_activation='relu', output_activation='sigmoid', q=0.50, l=0.01)\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam')\n",
    "\n",
    "# train\n",
    "history = model.fit(x=[train_x, train_x_users], y=train_x,\n",
    "                    batch_size=128, epochs=100, verbose=0,\n",
    "                    validation_data=[[test_x, test_x_users], test_x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success Rate at 1: 27.465536\n",
      "Success Rate at 2: 38.494168\n",
      "Success Rate at 3: 45.068929\n",
      "Success Rate at 4: 49.098621\n",
      "Success Rate at 5: 51.325557\n",
      "Success Rate at 6: 52.810180\n",
      "Success Rate at 7: 53.976670\n",
      "Success Rate at 8: 55.037116\n",
      "Success Rate at 9: 55.991516\n",
      "Success Rate at 10: 56.733828\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "pred = model.predict(x=[train_x, numpy.array(train_users, dtype=numpy.int32).reshape(len(train_users), 1)])\n",
    "pred = pred * (train_x == 0) # remove watched items from predictions\n",
    "pred = numpy.argsort(pred)\n",
    "\n",
    "for n in range(1, 11):\n",
    "    sr = success_rate(pred[:, -n:], test_x)\n",
    "    print(\"Success Rate at {:d}: {:f}\".format(n, sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
